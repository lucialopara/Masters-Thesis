{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66791a6b-560b-4fdc-87ea-a4776da8646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load necessary modules -------------------------------\n",
    "# interactive plotting\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg' # ‘png’, ‘retina’, ‘jpeg’, ‘svg’, ‘pdf’\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "sns.set_theme()\n",
    "\n",
    "# Data management libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from neuralsens import partial_derivatives as ns\n",
    "\n",
    "#Clustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.vq import vq\n",
    "from sklearn.metrics import silhouette_score\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import cmeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "#Profiling\n",
    "import line_profiler\n",
    "from line_profiler import LineProfiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "from funciones_limpieza import *\n",
    "from funciones_clustering import *\n",
    "from utils_aprendizaje_no_supervisado import * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27305f14-dfe3-44c5-a01d-bd88345a1790",
   "metadata": {},
   "source": [
    "# Preprocesado y cálculo PCA datos parque Myrtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57886763-4aeb-4951-8025-bc35f1dc44a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n",
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n"
     ]
    }
   ],
   "source": [
    "carpeta = '/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Datos_TFMGamesa/Datos Parque MYRTLE/Plots Myrtle'\n",
    "pca, X_pca = preprocesado_y_pca(carpeta, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc43fbb-2c57-4ca5-885d-2af6ace8af9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9071790"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nos quedamos con las tres primeras componentes principales pues vimos que eran las más representativas\n",
    "X_pca_3 = X_pca[:, :3]\n",
    "X_pca_3.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69959c-fddc-4e5d-9aad-19f0be0c11a6",
   "metadata": {},
   "source": [
    "# C-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459681d-ab42-4794-b874-9d18bf929316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_index(X, centroids, u):\n",
    "    \"\"\"\n",
    "    Cálculo del índice de Dunn para evaluar la calidad del clustering.\n",
    "    \"\"\"\n",
    "    # Distancia mínima entre dos centros de clusters\n",
    "    inter_cluster_dist = np.min(cdist(centroids, centroids))\n",
    "    \n",
    "    # Máxima distancia intra-cluster entre puntos y sus centros\n",
    "    intra_cluster_dist = 0\n",
    "    for i in range(len(centroids)):\n",
    "        cluster_points = X[np.argmax(u == i, axis=0)]  # Puntos del cluster\n",
    "        intra_cluster_dist = max(intra_cluster_dist, np.max(cdist(cluster_points, [centroids[i]])))\n",
    "    \n",
    "    return inter_cluster_dist / intra_cluster_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac6557-f4fa-49ed-91e4-e0df3182ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_cmeans_cross_validation(X, n_clusters=2, m_values=[1.5, 2.0, 2.5], error_values=[0.001, 0.005, 0.01], maxiter_values=[100, 200, 500]):\n",
    "    \"\"\"\n",
    "    Validación cruzada para optimizar los parámetros de Fuzzy C-Means y graficar el índice de Dunn.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    - X: Matriz de datos (tamaño: n_samples x n_features)\n",
    "    - n_clusters: Número de clusters (fijo en 2 para este caso)\n",
    "    - m_values: Lista de valores para el parámetro de difusividad\n",
    "    - error_values: Lista de valores para el parámetro de tolerancia de error\n",
    "    - maxiter_values: Lista de valores para el número máximo de iteraciones\n",
    "\n",
    "    Devuelve:\n",
    "    --------\n",
    "    - El conjunto de parámetros con el mejor índice de Dunn\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparar el KFold para la validación cruzada\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Inicializar la mejor métrica\n",
    "    best_dunn = -np.inf\n",
    "    best_params = None\n",
    "    \n",
    "    # Para almacenar los resultados de Dunn\n",
    "    results = []\n",
    "    \n",
    "    # Hacer un barrido sobre todos los parámetros posibles\n",
    "    for m in m_values:\n",
    "        for error in error_values:\n",
    "            for maxiter in maxiter_values:\n",
    "                print(f\"Evaluando parámetros: m={m}, error={error}, maxiter={maxiter}\")\n",
    "                \n",
    "                # Listar los Dunns para cada fold\n",
    "                dunn_scores = []\n",
    "                \n",
    "                # Realizar la validación cruzada\n",
    "                for train_idx, test_idx in kf.split(X):\n",
    "                    X_train, X_test = X[train_idx], X[test_idx]\n",
    "                    \n",
    "                    # Aplicar Fuzzy C-Means a los datos de entrenamiento\n",
    "                    cntr, u, u0, d, jm, p, fpc = cmeans(\n",
    "                        X_train.T,  # Datos transpuestos\n",
    "                        c=n_clusters,  # Número de clusters\n",
    "                        m=m,  # Difusividad\n",
    "                        error=error,  # Tolerancia de error\n",
    "                        maxiter=maxiter,  # Máximas iteraciones\n",
    "                        init=None,  # Inicialización automática\n",
    "                        seed=42  # Semilla para reproducibilidad\n",
    "                    )\n",
    "                    \n",
    "                    # Obtener los centroides\n",
    "                    centroids = cntr\n",
    "                    \n",
    "                    # Calcular el índice de Dunn para este pliegue\n",
    "                    dunn_score = dunn_index(X_test, centroids, u)\n",
    "                    dunn_scores.append(dunn_score)\n",
    "                \n",
    "                # Promediar los resultados de la validación cruzada\n",
    "                mean_dunn = np.mean(dunn_scores)\n",
    "                print(f\"Índice de Dunn promedio para m={m}, error={error}, maxiter={maxiter}: {mean_dunn}\")\n",
    "                \n",
    "                # Guardar los resultados para el gráfico\n",
    "                results.append((m, error, maxiter, mean_dunn))\n",
    "                \n",
    "                # Si encontramos un mejor índice de Dunn, guardamos los parámetros\n",
    "                if mean_dunn > best_dunn:\n",
    "                    best_dunn = mean_dunn\n",
    "                    best_params = (m, error, maxiter)\n",
    "    \n",
    "    # Convertir los resultados a un array de numpy para facilidad de uso\n",
    "    results = np.array(results)\n",
    "    \n",
    "    # Crear el gráfico\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Graficar el índice de Dunn para cada combinación de parámetros\n",
    "    scatter = ax.scatter(results[:, 0], results[:, 1], c=results[:, 3], cmap='viridis', s=100, edgecolors='black')\n",
    "    ax.set_xlabel('m (Coef. de Difusividad)')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title('Evolución del Índice de Dunn con los Parámetros')\n",
    "\n",
    "    # Añadir barra de color para mostrar los valores del índice de Dunn\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Índice de Dunn')\n",
    "    \n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mejores parámetros encontrados: m={best_params[0]}, error={best_params[1]}, maxiter={best_params[2]}\")\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a99ed67-48c3-4fb7-bdeb-35228a555e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuzzy_cmeans_cross_validation(X_pca_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a686c-9f22-4019-8e35-25b2d9fd3115",
   "metadata": {},
   "source": [
    "#### ENTRENO CMEANS CON 2 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33936c66-f44b-4039-a5f3-3aa670e648d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transponer X_pca porque skfuzzy espera datos como (n_features, n_samples)\n",
    "X_pca_3_T = X_pca_3.T\n",
    "\n",
    "# Aplicar Fuzzy C-Means con 2 clusters\n",
    "n_clusters = 2\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    X_pca_3_T,           # Datos (transpuestos)\n",
    "    c=n_clusters,      # Número de clusters\n",
    "    m=2.0,             # Coef. de difusividad (mayor → más difuso)\n",
    "    error=0.005,       # Tolerancia de error (Criterio de parada: cambio mínimo en la matriz de pertenencias)\n",
    "    maxiter=1000,      # Iteraciones máximas\n",
    "    init=None,         # Inicialización automática de pertenencias (u0)\n",
    "    seed=42            # Para reproducibilidad\n",
    ")\n",
    "\n",
    "#BREVE EXPLICACIÓN\n",
    "#-----------------\n",
    "#Fuzzy C-Means es un algoritmo de clustering difuso, lo que significa que cada punto puede pertenecer parcialmente a varios clusters. A \n",
    "#diferencia de K-Means (clustering duro), donde un punto pertenece a un solo cluster, FCM asigna un grado de pertenencia a cada punto con \n",
    "#respecto a cada cluster.\n",
    "\n",
    "#¿Cómo funciona el algoritmo?\n",
    "#1. Inicialización\n",
    "#Se elige el número de clusters c (por ejemplo, n_clusters = 2). \n",
    "#Se inicializa aleatoriamente una matriz de pertenencia u (de tamaño c × n) donde u[i, j] es el grado de pertenencia del punto j al cluster i.\n",
    "#El parámetro m > 1 (normalmente m=2) controla cuán difusa es esa pertenencia.\n",
    "\n",
    "#2. Iteración\n",
    "#El algoritmo sigue este ciclo:\n",
    "#a) Actualizar centroides (centros de clusters): Cada centroide v_i se actualiza como un promedio ponderado de los puntos, ponderado por los\n",
    "#grados de pertenencia elevados a m\n",
    "\n",
    "#b) Actualizar matriz de pertenencia u: Cada u_{ij} se calcula en función de la distancia entre el punto x_j y el centro v_i\n",
    "#Esto asegura que:\n",
    "#Si un punto está más cerca de un centroide, tendrá una mayor pertenencia a ese cluster.\n",
    "#Las pertenencias de un punto a todos los clusters suman 1.\n",
    "\n",
    "#c) Criterio de parada:\n",
    "#Se mide el cambio en la matriz de pertenencia entre iteraciones sucesivas. Si ese cambio es menor que el parámetro error, o se alcanzan \n",
    "#maxiter iteraciones, se detiene el algoritmo.\n",
    "\n",
    "\n",
    "#EXPLICACIÓN PARÁMETROS\n",
    "#----------------------\n",
    "#- X_pca_T:\tMatriz de datos transpuesta: filas = características, columnas = puntos\n",
    "#- c: Número de clusters a encontrar\n",
    "#- m: Fuzziness exponent: mide el grado de superposición entre clusters.\n",
    "#          Si m → 1, el modelo se parece a K-Means (menos difuso)\n",
    "#          Si m > 1, los clusters son más difusos (común usar m = 2)\n",
    "#- error: Umbral de convergencia: si el cambio entre iteraciones es menor, se detiene\n",
    "#- maxiter: Número máximo de iteraciones que permite\n",
    "#- init: Matriz de pertenencias inicial (puede dejarse como None)\n",
    "#- seed: Fija la aleatoriedad de la inicialización para que el resultado sea reproducible\n",
    "\n",
    "#EXPLICACIÓN SALIDA\n",
    "#------------------\n",
    "#- cntr: Matriz con los centroides difusos de los clusters (shape: c x features)\n",
    "#- u: Matriz final de pertenencias (shape: c x n_samples)\n",
    "#- u0: Matriz de pertenencias iniciales (antes de empezar a iterar)\n",
    "#- d: Distancia de cada punto a cada centro (usada internamente)\n",
    "#- jm: Evolución del coste (función objetivo) en cada iteración\n",
    "#- p: Número de iteraciones hasta converger\n",
    "#- fpc: Fuzzy Partition Coefficient (entre 0 y 1). Cuanto más cercano a 1, mejor la partición (mide cuán claras son las asignaciones de pertenencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e67dc3f-d909-402c-8697-8346b3c1bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El índice FPC para nuestro modelo de C-means con dos clusters es: 0.838147808868499\n"
     ]
    }
   ],
   "source": [
    "#Vemos la calidad del clustering con FPC (Fuzzy Partition Coefficient). Es un valor entre 0 y 1:\n",
    "#- Cercano a 1: buena partición, los puntos tienen pertenencias claras (alta certeza).\n",
    "#- Cercano a 0: partición difusa, los puntos están muy mezclados entre clusters.\n",
    "print(f\"El índice FPC para nuestro modelo de C-means con dos clusters es: {fpc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03af6a66-3004-4c29-b626-3b3b379ff1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunn_index(X_pca_3, cntr, u) #nuestros centroides y clusters están muy juntos (se puede ver en la grafica PC2 vs PC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d74016-9141-466c-b192-7186c696ae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de muestras por cluster (C-Means):\n",
      "   # Samples  Percentage (%)\n",
      "0    1897981       62.765375\n",
      "1    1125949       37.234625\n"
     ]
    }
   ],
   "source": [
    "#Obtenemos las etiquetas de los cluster con el mayor grado de pertenencia para cada cluster (esto sería como el resultado obtenido con kmeans)\n",
    "\n",
    "# Asignar cada punto al cluster con mayor grado de pertenencia\n",
    "cluster_labels_cmeans = np.argmax(u, axis=0)\n",
    "\n",
    "# Contar elementos por cluster\n",
    "unique, counts = np.unique(cluster_labels_cmeans, return_counts=True)\n",
    "\n",
    "# Calcular porcentaje\n",
    "total_samples = len(cluster_labels_cmeans)\n",
    "percentages = (counts / total_samples) * 100\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "df_clusters_cmeans = pd.DataFrame({\n",
    "    '# Samples': counts,\n",
    "    'Percentage (%)': percentages\n",
    "}, index=unique)\n",
    "\n",
    "# Mostrar resultados\n",
    "print('Distribución de muestras por cluster (C-Means):')\n",
    "print(df_clusters_cmeans)\n",
    "\n",
    "\n",
    "#Tenemos más puntos en el cluster 0 que en el 1 (número de elementos en los clusters similares a Kmeans pero en este caso tenemos algo más de \n",
    "#elementos en el cluster 1 esto puede deberse a puntos con grados de pertenencia similares en los dos clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f88f2e-4a11-4f9d-9c4c-f1ead7373e48",
   "metadata": {},
   "source": [
    "#### VISUALIZACIÓN CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2545d326-b609-43e4-a449-5d399cc94e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener etiquetas predichas (máxima pertenencia)\n",
    "cluster_labels = np.argmax(u, axis=0)\n",
    "\n",
    "# Obtener los centros de los clusters desde C-means\n",
    "cluster_centers = cntr  # asumimos que esta variable contiene los centroides\n",
    "\n",
    "# Muestrear un pequeño porcentaje de los datos para visualizar\n",
    "sample_size = int(X_pca_3.shape[0] * 1)  # 100% en este caso\n",
    "sampled_indices = np.random.choice(X_pca_3.shape[0], sample_size, replace=False)\n",
    "sampled_X = X_pca_3[sampled_indices, :]\n",
    "sampled_labels = cluster_labels[sampled_indices]\n",
    "\n",
    "# Número de componentes principales\n",
    "n_components = X_pca_3.shape[1]\n",
    "pairs = list(combinations(range(n_components), 2))\n",
    "\n",
    "# Crear subgráficos\n",
    "fig, axes = plt.subplots(len(pairs), 1, figsize=(6, len(pairs) * 3))\n",
    "if len(pairs) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Visualización por pares de componentes principales\n",
    "for idx, (i, j) in enumerate(pairs):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Scatter por clúster para añadir leyenda\n",
    "    for cluster_id in np.unique(sampled_labels):\n",
    "        cluster_points = sampled_X[sampled_labels == cluster_id]\n",
    "        ax.scatter(\n",
    "            cluster_points[:, i], cluster_points[:, j],\n",
    "            label=f\"Cluster {cluster_id}\",\n",
    "            alpha=0.5,\n",
    "            s=10\n",
    "        )\n",
    "\n",
    "    # Visualización de los centros\n",
    "    ax.scatter(\n",
    "        cluster_centers[:, i], cluster_centers[:, j],\n",
    "        c='red', marker='X', s=80, label=\"Centroides\"\n",
    "    )\n",
    "\n",
    "    # Ajustar ejes al rango de los puntos\n",
    "    ax.set_xlim([sampled_X[:, i].min() - 0.5, sampled_X[:, i].max() + 0.5])\n",
    "    ax.set_ylim([sampled_X[:, j].min() - 0.5, sampled_X[:, j].max() + 0.5])\n",
    "\n",
    "    ax.set_title(f\"C-means: PC{i+1} vs PC{j+1}\")\n",
    "    ax.set_xlabel(f\"PC{i+1}\")\n",
    "    ax.set_ylabel(f\"PC{j+1}\")\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "# Ajustar disposición y guardar\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/Imagenes/CMeans/clusters_cmeans_k2_PCA3.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0b58b-d3d9-4e8b-a9d1-c4afd761a194",
   "metadata": {},
   "source": [
    "#### VALOR MEDIO PCA DE LOS CENTROIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb3f50e2-cb5e-40a9-b779-21aca766da7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.57746074  0.29083528  0.21206906]\n",
      " [ 5.86637901 -0.20482372  0.11343113]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wn/gxtmyy811gg8d_h61xk9hfkm0000gn/T/ipykernel_3662/1635054801.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=range(n_clusters), y=cluster_centers[:,i], edgecolor='black', palette='viridis')\n",
      "/var/folders/wn/gxtmyy811gg8d_h61xk9hfkm0000gn/T/ipykernel_3662/1635054801.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=range(n_clusters), y=cluster_centers[:,i], edgecolor='black', palette='viridis')\n",
      "/var/folders/wn/gxtmyy811gg8d_h61xk9hfkm0000gn/T/ipykernel_3662/1635054801.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=range(n_clusters), y=cluster_centers[:,i], edgecolor='black', palette='viridis')\n"
     ]
    }
   ],
   "source": [
    "# Saber el valor medio que tienen los centroides de un cluster nos dará una idea intuitiva de los valores que toman para cada PCA los \n",
    "# puntos de un cluster\n",
    "\n",
    "# Print values of the cluster centers\n",
    "n_clusters = 2\n",
    "print(cluster_centers) #los centroides están en el espacio de PCA\n",
    "\n",
    "# Plot the values of the cluster center\n",
    "for i in range(cluster_centers.shape[1]):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.barplot(x=range(n_clusters), y=cluster_centers[:,i], edgecolor='black', palette='viridis')\n",
    "    plt.xticks(range(n_clusters))\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('PC{}'.format(i+1))\n",
    "    plt.title('Cluster centers for PC{}'.format(i+1))\n",
    "\n",
    "    # Guardar la imagen en lugar de mostrarla\n",
    "    # Aquí puedes cambiar la ruta y el nombre del archivo según lo desees\n",
    "    nombre_archivo = f'/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/Imagenes/Cmeans/Cmeans2_cluster_centers_PC{i+1}.png'  # Nombre del archivo de la imagen\n",
    "    plt.savefig(nombre_archivo, dpi=300)  # Guarda la imagen con alta resolución\n",
    "    plt.close()  # Cierra la figura después de guardarla para evitar que se acumulen múltiples gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25584887-1292-4e5f-b871-0cbb97e0d457",
   "metadata": {},
   "source": [
    "#### GRADOS DE PERTENENCIA CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a3de2a-7506-4b66-99e3-efb29418cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a crear un histograma en el que podamos ver para cada cluster la cantidad de puntos que pertenecen a ese cluster con cierto grado de \n",
    "#pertenencia. Si hay muchos puntos en grados de pertenencia cercanos a 1 indica que los puntos se han asignado con claridad ese cluster.\n",
    "\n",
    "# Crear una figura para todos los histogramas\n",
    "fig, axes = plt.subplots(n_clusters, 1, figsize=(8, 4 * n_clusters))\n",
    "\n",
    "# Si solo hay un clúster, convertir axes en lista para que sea iterable\n",
    "if n_clusters == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    # Seleccionar grados de pertenencia de los puntos asignados al cluster i\n",
    "    pertenencias = u[i, cluster_labels == i]\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.hist(pertenencias, bins=20, color='skyblue', edgecolor='black')\n",
    "    ax.set_title(f'Grados de pertenencia para el Clúster {i}')\n",
    "    ax.set_xlabel('Grado de pertenencia')\n",
    "    ax.set_ylabel('Cantidad de puntos')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar imagen (puedes cambiar el nombre dinámicamente si quieres)\n",
    "plt.savefig('/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/Imagenes/CMeans/GradosPertenencia_cmeans_k2_PCA3.png')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "#Vemos que la mayoría de puntos pertenecen a cada cluster con grados de pertenencia cercanos a uno por lo que los clusters son bastante \n",
    "#robustos. Los puntos con mennores grados de pertenencia pueden ser puntos situados en las fronteras de los clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308bf2a-fbc7-4133-9e13-712eda95cfbe",
   "metadata": {},
   "source": [
    "### Ahora probamos este clustering con los datos de inversores con un funcionamiento a priori normal y uno con comportamiento anómalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6652869-1798-4c6e-88d0-9c1b5c39d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a considerar el inversor 34 y el 11 del día 13-02-25. Sabemos que el inversor 11 tuvo fallo de explosión tras congelar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3774b9d-f024-4eee-94b2-b3c10d2679f2",
   "metadata": {},
   "source": [
    "#### INVERSOR 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e8c252a-9171-45f7-a0e7-05e8428caf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "129573"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LECTURA Y PPREPROCESADO INVERSOR 11\n",
    "#-----------------------------------\n",
    "\n",
    "carpeta_explosion_congelar = '/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Datos_TFMGamesa/FalloExplosionTrasCongelarPruebas 13_02_25/inv11'\n",
    "X_pca_explosion_congelar = aplicar_pca_datos(carpeta_explosion_congelar, pca)\n",
    "# Seleccionar las primeras 3 componentes principales\n",
    "X_pca_3_explosion_congelar = X_pca_explosion_congelar[:, :3]\n",
    "X_pca_3_explosion_congelar.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e20b616c-5b99-4de4-aa7e-db48ece79fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 28271 elementos (65.46%)\n",
      "Cluster 1: 14920 elementos (34.54%)\n"
     ]
    }
   ],
   "source": [
    "# Asignar a cada punto el cluster con mayor pertenencia\n",
    "\n",
    "# Transponer los nuevos datos igual que los originales\n",
    "X_pca_3_explosion_congelar_T = X_pca_3_explosion_congelar.T\n",
    "\n",
    "# Predecir los grados de pertenencia para los nuevos datos\n",
    "u_explosion_congelar, _, _, _, _, _ = fuzz.cluster.cmeans_predict(\n",
    "    test_data = X_pca_3_explosion_congelar_T,\n",
    "    cntr_trained = cntr,\n",
    "    m         = 2.0,\n",
    "    error     = 0.005,\n",
    "    maxiter   = 1000\n",
    ")\n",
    "clusters_predichos_explosion_congelar = np.argmax(u_explosion_congelar, axis=0)\n",
    "\n",
    "# Número total de elementos\n",
    "total_elements = clusters_predichos_explosion_congelar.shape[0]\n",
    "\n",
    "# Contar elementos por clúster\n",
    "cluster_counts = np.bincount(clusters_predichos_explosion_congelar)\n",
    "\n",
    "# Mostrar resultados\n",
    "for cluster_id, count in enumerate(cluster_counts):\n",
    "    percentage = (count / total_elements) * 100\n",
    "    print(f\"Cluster {cluster_id}: {count} elementos ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dab568bb-9cce-4e2e-988f-510ced26b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener etiquetas predichas por C-means (usamos los grados de pertenencia y asignamos el cluster con mayor pertenencia)\n",
    "clusters_predichos_cmeans = np.argmax(u_explosion_congelar, axis=0)\n",
    "\n",
    "# Obtener los centros de los clusters (esto es cntr en C-means)\n",
    "cluster_centers_cmeans = cntr\n",
    "\n",
    "# Muestrear un pequeño porcentaje de los datos para visualizar\n",
    "sample_size = int(X_pca_3_explosion_congelar.shape[0] * 1)  # 100% en este caso, puedes ajustar\n",
    "sampled_indices = np.random.choice(X_pca_3_explosion_congelar.shape[0], sample_size, replace=False)\n",
    "sampled_X = X_pca_3_explosion_congelar[sampled_indices, :]\n",
    "sampled_labels = clusters_predichos_cmeans[sampled_indices]\n",
    "\n",
    "# Número de componentes principales\n",
    "n_components = X_pca_3_explosion_congelar.shape[1]\n",
    "pairs = list(combinations(range(n_components), 2))\n",
    "\n",
    "# Crear los subgráficos\n",
    "fig, axes = plt.subplots(len(pairs), 1, figsize=(6, len(pairs) * 3))\n",
    "if len(pairs) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Visualización por pares de componentes principales\n",
    "for idx, (i, j) in enumerate(pairs):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Creamos un scatter plot para cada cluster individual para poder añadir la leyenda\n",
    "    for cluster_id in np.unique(sampled_labels):\n",
    "        cluster_points = sampled_X[sampled_labels == cluster_id]\n",
    "        ax.scatter(\n",
    "            cluster_points[:, i], cluster_points[:, j],\n",
    "            label=f\"Cluster {cluster_id}\",\n",
    "            alpha=0.5,\n",
    "            s=10\n",
    "        )\n",
    "\n",
    "    # Visualización de los centros (centroides de C-means)\n",
    "    ax.scatter(\n",
    "        cluster_centers_cmeans[:, i], cluster_centers_cmeans[:, j],\n",
    "        c='red', marker='X', s=80, label=\"Centroides\"\n",
    "    )\n",
    "\n",
    "    ax.set_xlim([sampled_X[:, i].min() - 1, sampled_X[:, i].max() + 1])\n",
    "    ax.set_ylim([sampled_X[:, j].min() - 1, sampled_X[:, j].max() + 1])\n",
    "\n",
    "    ax.set_title(f\"PC{i+1} vs PC{j+1}\")\n",
    "    ax.set_xlabel(f\"PC{i+1}\")\n",
    "    ax.set_ylabel(f\"PC{j+1}\")\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "# Ajustar disposición y guardar\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/Imagenes/CMeans/DistribucionClusters_CMeans2_inv11Dia130225.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d19ba-ed3c-4f1c-bdb3-097d1d5f585a",
   "metadata": {},
   "source": [
    "#### INVERSOR 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c56ef92-d5b8-4aa9-a48e-4f7427fd4688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/funciones_limpieza.py:124: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  plots = pd.read_csv(nombre_csv, index_col = False, sep = \";\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "129597"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LECTURA Y PPREPROCESADO INVERSOR 34\n",
    "#-----------------------------------\n",
    "\n",
    "carpeta_inv34_130225 = '/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Datos_TFMGamesa/FalloExplosionTrasCongelarPruebas 13_02_25/inv34'  \n",
    "X_pca_inv34_130225 = aplicar_pca_datos(carpeta_inv34_130225, pca)\n",
    "# Seleccionar las primeras 3 componentes principales\n",
    "X_pca_3_inv34_130225 = X_pca_inv34_130225[:, :3]\n",
    "X_pca_3_inv34_130225.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd9ca42-99fa-430d-b91d-39688e3a66c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 26555 elementos (61.47%)\n",
      "Cluster 1: 16644 elementos (38.53%)\n"
     ]
    }
   ],
   "source": [
    "# Asignar a cada punto el cluster con mayor pertenencia\n",
    "\n",
    "# Transponer los nuevos datos igual que los originales\n",
    "X_pca_3_inv34_130225_T = X_pca_3_inv34_130225.T\n",
    "\n",
    "# Predecir los grados de pertenencia para los nuevos datos\n",
    "u_inv34_130225, _, _, _, _, _ = fuzz.cluster.cmeans_predict(\n",
    "    test_data = X_pca_3_inv34_130225_T,\n",
    "    cntr_trained = cntr,\n",
    "    m         = 2.0,\n",
    "    error     = 0.005,\n",
    "    maxiter   = 1000\n",
    ")\n",
    "clusters_predichos_inv34_130225 = np.argmax(u_inv34_130225, axis=0)\n",
    "\n",
    "# Número total de elementos\n",
    "total_elements = clusters_predichos_inv34_130225.shape[0]\n",
    "\n",
    "# Contar elementos por clúster\n",
    "cluster_counts = np.bincount(clusters_predichos_inv34_130225)\n",
    "\n",
    "# Mostrar resultados\n",
    "for cluster_id, count in enumerate(cluster_counts):\n",
    "    percentage = (count / total_elements) * 100\n",
    "    print(f\"Cluster {cluster_id}: {count} elementos ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68b184a5-949c-4ce3-bc0f-889a12d69865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener etiquetas predichas por C-means (usamos los grados de pertenencia y asignamos el cluster con mayor pertenencia)\n",
    "clusters_predichos_cmeans = np.argmax(u_inv34_130225, axis=0)\n",
    "\n",
    "# Obtener los centros de los clusters (esto es cntr en C-means)\n",
    "cluster_centers_cmeans = cntr\n",
    "\n",
    "# Muestrear un pequeño porcentaje de los datos para visualizar\n",
    "sample_size = int(X_pca_3_inv34_130225.shape[0] * 1)  # 100% en este caso, puedes ajustar\n",
    "sampled_indices = np.random.choice(X_pca_3_inv34_130225.shape[0], sample_size, replace=False)\n",
    "sampled_X = X_pca_3_inv34_130225[sampled_indices, :]\n",
    "sampled_labels = clusters_predichos_cmeans[sampled_indices]\n",
    "\n",
    "# Número de componentes principales\n",
    "n_components = X_pca_3_inv34_130225.shape[1]\n",
    "pairs = list(combinations(range(n_components), 2))\n",
    "\n",
    "# Crear los subgráficos\n",
    "fig, axes = plt.subplots(len(pairs), 1, figsize=(6, len(pairs) * 3))\n",
    "if len(pairs) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Visualización por pares de componentes principales\n",
    "for idx, (i, j) in enumerate(pairs):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Creamos un scatter plot para cada cluster individual para poder añadir la leyenda\n",
    "    for cluster_id in np.unique(sampled_labels):\n",
    "        cluster_points = sampled_X[sampled_labels == cluster_id]\n",
    "        ax.scatter(\n",
    "            cluster_points[:, i], cluster_points[:, j],\n",
    "            label=f\"Cluster {cluster_id}\",\n",
    "            alpha=0.5,\n",
    "            s=10\n",
    "        )\n",
    "\n",
    "    # Visualización de los centros (centroides de C-means)\n",
    "    ax.scatter(\n",
    "        cluster_centers_cmeans[:, i], cluster_centers_cmeans[:, j],\n",
    "        c='red', marker='X', s=80, label=\"Centroides\"\n",
    "    )\n",
    "\n",
    "    ax.set_xlim([sampled_X[:, i].min() - 1, sampled_X[:, i].max() + 1])\n",
    "    ax.set_ylim([sampled_X[:, j].min() - 1, sampled_X[:, j].max() + 1])\n",
    "\n",
    "    ax.set_title(f\"PC{i+1} vs PC{j+1}\")\n",
    "    ax.set_xlabel(f\"PC{i+1}\")\n",
    "    ax.set_ylabel(f\"PC{j+1}\")\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "# Ajustar disposición y guardar\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/lucialopez/Documents/MBD/Segundo_cuatrimestre/TFM/Clustering/Imagenes/CMeans/DistribucionClusters_CMeans2_inv34Dia130225.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df62edb0-7bc3-4f68-9c72-faa1e62befe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(X_pca_3_explosion_congelar.shape[0])\n",
    "print(X_pca_3_inv34_130225.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97980e91-537f-482d-8bfc-8adde09e62f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
